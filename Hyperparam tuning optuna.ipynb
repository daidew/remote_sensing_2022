{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43969c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_edf\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_slice\n",
    "import optuna\n",
    "study = optuna.study.load_study('no-name-2381af36-3492-486c-b2b5-e4ebe82eeb83')\n",
    "# joblib.dump(study, \"study_5_IMGS_AVG_OBJ.pkl\")\n",
    "\n",
    "import joblib\n",
    "study = joblib.load(\"study_5_IMGS_AVG_OBJ.pkl\")\n",
    "print(\"Best trial until now:\")\n",
    "print(\" Value: \", study.best_trial.value)\n",
    "print(\" Params: \")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "    \n",
    "plot_optimization_history(study, target=lambda t:np.mean(t.values[1]))\n",
    "\n",
    "plot_contour(study)\n",
    "\n",
    "plot_contour(study, target=lambda t:np.mean(t.user_attrs['r']), target_name='r')\n",
    "\n",
    "plot_contour(study, target=lambda t:np.log(np.mean(t.user_attrs['num_nodes'])), target_name='log num_nodes')\n",
    "\n",
    "plot_contour(study, target=lambda t:np.std(t.user_attrs['r']), target_name='std r')\n",
    "\n",
    "plot_contour(study, target=lambda t:np.std(t.user_attrs['num_nodes']), target_name='std num_nodes')\n",
    "\n",
    "plot_slice(study,target=lambda t:np.mean(t.user_attrs['r']), target_name='r')\n",
    "\n",
    "plot_slice(study,target=lambda t:np.mean(t.user_attrs['num_nodes']), target_name='num_nodes')\n",
    "\n",
    "optuna.visualization.plot_pareto_front(study, target_names=[\"r\", \"num_nodes\"])\n",
    "\n",
    "with open('10IMGS_optuna_multi_obj.txt', 'r') as f2:\n",
    "    arr = [[float(x) for x in t.strip().split()] for t in f2.readlines()]\n",
    "len(arr)\n",
    "\n",
    "\n",
    "num_nodes_lst = []\n",
    "r_lst = []\n",
    "thresh_lst  = []\n",
    "cnt_area_max_lst = []\n",
    "\n",
    "for num_nodes, r, thresh, cnt_area_max in arr:\n",
    "    num_nodes_lst.append(num_nodes)\n",
    "    r_lst.append(r)\n",
    "    thresh_lst.append(thresh)\n",
    "    cnt_area_max_lst.append(cnt_area_max)\n",
    "    \n",
    "    \n",
    "pareto_front = np.zeros(len(arr), dtype=bool)\n",
    "par = []\n",
    "for i in range(len(arr)):\n",
    "    dom = False\n",
    "    for j in range(len(arr)):\n",
    "        if i != j and arr[j][0] < arr[i][0] and arr[j][1] > arr[i][1]: # pt. j dominates pt. i if num_nodes_j < num_nodes_i and r_j > r_i\n",
    "            dom = True\n",
    "    if not dom: #pareto front\n",
    "        pareto_front[i] = True\n",
    "        par.append((arr[i][1], arr[i][0]))\n",
    "\n",
    "        \n",
    "plt.figure(dpi=200)\n",
    "plt.scatter(x=r_lst, y=num_nodes_lst, s=30, c='blue',  edgecolors= \"black\", linewidth=0.5)\n",
    "# plt.title('Min r among random 10 images per hyperparams evaluation')\n",
    "arr2 = np.array(sorted(par, key = lambda t: t[0]))\n",
    "plt.plot(arr2[:, 0], arr2[:, 1], c='red', label='pareto front')\n",
    "for i in range(arr2.shape[0]):\n",
    "    plt.text(arr2[i][0]+0.001, arr2[i][1]-500, f'({np.around(arr2[i][0],3)}, {int(arr2[i][1])})', fontsize=4, color='red')\n",
    "plt.title('Trade-offs for varying (thresh, cnt_area_max) in the BFS algorithm')\n",
    "plt.xlabel('min r among 20 imgs.')\n",
    "plt.ylabel('max num_nodes among 20 imgs.')\n",
    "plt.legend()        \n",
    "\n",
    "from matplotlib import colors\n",
    "divnorm=colors.TwoSlopeNorm(vmin=0., vcenter=0.9, vmax=1)\n",
    "plt.figure(dpi=200)\n",
    "for i in range(len(arr)):\n",
    "    plt.scatter(x=thresh_lst[i],y=cnt_area_max_lst[i] , c=r_lst[i], s=30, cmap='seismic', norm=divnorm, edgecolors= \"black\", linewidth=0.5)\n",
    "plt.title('Min r among random 20 images per hyperparams evaluation')\n",
    "plt.xlabel('log thresh')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('cnt_area_max')\n",
    "plt.ylim(0, 200)\n",
    "plt.colorbar(label='r')\n",
    "\n",
    "from matplotlib import colors\n",
    "divnorm=colors.TwoSlopeNorm(vmin=0., vcenter=7000, vmax=20000)\n",
    "plt.figure(dpi=200)\n",
    "for i in range(len(arr)):\n",
    "    plt.scatter(x=thresh_lst[i],y=cnt_area_max_lst[i], c=num_nodes_lst[i], s=30, cmap='PiYG', edgecolors= \"black\", linewidth=0.5, norm=divnorm)\n",
    "\n",
    "plt.title('Max num_nodes among random 20 images per hyperparams evaluation')\n",
    "plt.xlabel('log thresh')\n",
    "plt.ylabel('cnt_area_max')\n",
    "plt.ylim(0, 200)\n",
    "plt.xscale('log')\n",
    "plt.colorbar(label='num_nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9517ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "NUM_IMG = 5\n",
    "R_WEIGHT = 100000\n",
    "def objective(trial):\n",
    "\n",
    "    # Invoke suggest methods of a Trial object to generate hyperparameters.\n",
    "    thresh = trial.suggest_loguniform('thresh', 0.0001, 1)\n",
    "    cnt_area_max = trial.suggest_uniform('cnt_area_max',1, 200)\n",
    "    r_lst, num_nodes_lst, chosen_idx_lst = [], [], []\n",
    "    for _ in range(NUM_IMG):\n",
    "        chosen_idx = np.random.randint(len(train_data))\n",
    "        chosen_idx_lst.append(chosen_idx)\n",
    "        \n",
    "        img, msk, fn = train_data[chosen_idx]\n",
    "        \n",
    "        img = np.moveaxis(img.numpy(), 0, -1)\n",
    "        msk_discrete = np.argmax(msk.numpy(), axis=0)\n",
    "        dst = cv2.Canny(np.uint8(img*255), 50, 200, None, 3)\n",
    "        dst = dst>0\n",
    "        partition_res, mean_c_res, res_lst, cnt_res_lst, num_nodes = partition_image(dst, img, thresh=thresh, cnt_area_max=cnt_area_max)\n",
    "\n",
    "        r, _, _ = avg_acc(num_nodes, partition_res, res_lst, msk_discrete)\n",
    "        r_lst.append(r)\n",
    "        num_nodes_lst.append(num_nodes)\n",
    "        \n",
    "    trial.set_user_attr(\"r\", r_lst)\n",
    "    trial.set_user_attr(\"num_nodes\", num_nodes_lst)\n",
    "    trial.set_user_attr(\"chosen_idx\", chosen_idx_lst)\n",
    "    \n",
    "    obj = (np.sum(num_nodes_lst) - np.sum(r_lst)*R_WEIGHT)/NUM_IMG\n",
    "    \n",
    "    return obj\n",
    "\n",
    "def logging_callback(study, frozen_trial):\n",
    "#     study.set_user_attr(\"previous_best_value\", study.best_value)\n",
    "    print(\n",
    "        \"Trial {} finished with value: {} and parameters: {} | r = {}, num_nodes = {}, chosen_idx = {} \".format(\n",
    "        frozen_trial.number,\n",
    "        frozen_trial.value,\n",
    "        frozen_trial.params,\n",
    "        frozen_trial.user_attrs['r'],\n",
    "        frozen_trial.user_attrs['num_nodes'],\n",
    "        frozen_trial.user_attrs['chosen_idx']\n",
    "        )\n",
    "    )\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")  # Create a new study.\n",
    "study.optimize(objective, n_trials=100, callbacks=[logging_callback])  # Invoke optimization of the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f0cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "NUM_IMG = 20\n",
    "R_WEIGHT = 100000\n",
    "def objective(trial):\n",
    "\n",
    "    # Invoke suggest methods of a Trial object to generate hyperparameters.\n",
    "    thresh = trial.suggest_loguniform('thresh', 0.0001, 1)\n",
    "    cnt_area_max = trial.suggest_uniform('cnt_area_max',1, 200)\n",
    "    r_lst, num_nodes_lst, chosen_idx_lst = [], [], []\n",
    "    for _ in range(NUM_IMG):\n",
    "        chosen_idx = np.random.randint(len(train_data))\n",
    "        chosen_idx_lst.append(chosen_idx)\n",
    "        \n",
    "        img, msk, fn = train_data[chosen_idx]\n",
    "        \n",
    "        img = np.moveaxis(img.numpy(), 0, -1)\n",
    "        msk_discrete = np.argmax(msk.numpy(), axis=0)\n",
    "        dst = cv2.Canny(np.uint8(img*255), 50, 200, None, 3)\n",
    "        dst = dst>0\n",
    "        partition_res, mean_c_res, res_lst, cnt_res_lst, num_nodes = partition_image(dst, img, thresh=thresh, cnt_area_max=cnt_area_max)\n",
    "\n",
    "        r, _, _ = avg_acc(num_nodes, partition_res, res_lst, msk_discrete)\n",
    "        r_lst.append(r)\n",
    "        num_nodes_lst.append(num_nodes)\n",
    "        \n",
    "    trial.set_user_attr(\"r\", r_lst)\n",
    "    trial.set_user_attr(\"num_nodes\", num_nodes_lst)\n",
    "    trial.set_user_attr(\"chosen_idx\", chosen_idx_lst)\n",
    "    \n",
    "    return np.max(num_nodes_lst), np.min(r_lst)\n",
    "\n",
    "def logging_callback(study, frozen_trial):\n",
    "#     study.set_user_attr(\"previous_best_value\", study.best_value)\n",
    "    print(\n",
    "        \"Trial {} finished and parameters: {} | r = {}, num_nodes = {}, chosen_idx = {} \".format(\n",
    "        frozen_trial.number,\n",
    "        frozen_trial.params,\n",
    "        frozen_trial.user_attrs['r'],\n",
    "        frozen_trial.user_attrs['num_nodes'],\n",
    "        frozen_trial.user_attrs['chosen_idx']\n",
    "        )\n",
    "    )\n",
    "\n",
    "study = optuna.create_study(directions=[\"minimize\", \"maximize\"])  # Create a new study.\n",
    "study.optimize(objective, n_trials=100, callbacks=[logging_callback])  # Invoke optimization of the objective function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
